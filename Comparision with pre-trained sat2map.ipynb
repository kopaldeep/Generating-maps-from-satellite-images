{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacaccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained generator vs pre-trained sat2map - SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e766a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd35050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0a788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 512)),\n",
    "    transforms.CenterCrop((256, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c88294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    name = m.__class__.__name__\n",
    "    \n",
    "    if(name.find(\"Conv\") > -1):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02) # ~N(mean=0.0, std=0.02)\n",
    "    elif(name.find(\"BatchNorm\") > -1):\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "        \n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1848b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.encoder1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        \n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        \n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        \n",
    "        self.encoder5 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        \n",
    "        self.encoder6 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        \n",
    "        self.encoder7 = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        # skip connection in forward()\n",
    "        \n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=512*2, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        # skip connection in forward()\n",
    "        \n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=512*2, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        # skip connection in forward()\n",
    "        \n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=512*2, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            #nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.decoder5 = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=256*2, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            #nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.decoder6 = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=128*2, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            #nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.decoder7 = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=64*2, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "        e5 = self.encoder5(e4)\n",
    "        e6 = self.encoder6(e5)\n",
    "        \n",
    "        latent_space = self.encoder7(e6)\n",
    "        \n",
    "        d1 = torch.cat([self.decoder1(latent_space), e6], dim=1)\n",
    "        d2 = torch.cat([self.decoder2(d1), e5], dim=1)\n",
    "        d3 = torch.cat([self.decoder3(d2), e4], dim=1)\n",
    "        d4 = torch.cat([self.decoder4(d3), e3], dim=1)\n",
    "        d5 = torch.cat([self.decoder5(d4), e2], dim=1)\n",
    "        d6 = torch.cat([self.decoder6(d5), e1], dim=1)\n",
    "        \n",
    "        out = self.decoder7(d6)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab374bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['720', '454', '1026', '123', '111', '509', '233', '167', '1022', '1050']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_image(img, title=\"No title\", figsize=(5,5), fname='test'):\n",
    "    img = img.numpy().transpose(1,2,0)\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    \n",
    "    img = img * std + mean\n",
    "    np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.savefig(fname + '.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "test_names = []\n",
    "for name in os.listdir(data_dir + '/test_pro'):\n",
    "    if name[0] != '.':\n",
    "        test_names.append(name)\n",
    "test_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4306d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_test = datasets.ImageFolder(root=os.path.join(data_dir, \"test_pro\"), transform=data_transform)\n",
    "# dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# test_imgs,_ = next(iter(dataloader_test))\n",
    "\n",
    "model_G = torch.load('sat2mapGen_v1.3.pth')\n",
    "# model_G.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "290e03c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [-0.9921568632125854, 0.8117647171020508]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.6925315856933594, 0.9999802112579346]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.9686274528503418, 0.7490196228027344]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.3980623185634613, 0.999482274055481]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.8823529481887817, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.9607843160629272, 0.9372549057006836]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.799440324306488, 0.9999986290931702]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.8666666746139526, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.9607843160629272, 0.9921568632125854]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.28945156931877136, 0.9999905228614807]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.9137254953384399, 0.9764705896377563]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.6967548131942749, 0.9999597668647766]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.9215686321258545, 1.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.9450980424880981, 0.8745098114013672]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.21192456781864166, 0.9999997019767761]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.9529411792755127, 0.9450980424880981]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.9607843160629272, 0.9607843160629272]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.05787516385316849, 0.9999994039535522]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [-0.9450980424880981, 0.8666666746139526]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from imageio import imsave\n",
    "\n",
    "for img in os.listdir(data_dir + '/test_pro1'):\n",
    "    image = Image.open(data_dir + '/test_pro1/' + img) \n",
    "    image = data_transform(image)\n",
    "    \n",
    "    satellite = image[None, :, :, :256].to(device)\n",
    "    maps = image[None, :, :, 256:].to(device)\n",
    "    \n",
    "    gen = model_G(satellite)\n",
    "    \n",
    "    satellite = satellite.detach().cpu().numpy()\n",
    "    gen = gen.detach().cpu().numpy()\n",
    "    maps = maps.detach().cpu().numpy()\n",
    "    \n",
    "    satellite = np.moveaxis(satellite[0], 0, -1)\n",
    "    gen = np.moveaxis(gen[0], 0, -1)\n",
    "    maps = np.moveaxis(maps[0], 0, -1)\n",
    "    \n",
    "    imsave(img[:-4] + '_real_B.jpg', satellite)\n",
    "    imsave(img[:-4] + '_fake.jpg', gen)\n",
    "    imsave(img[:-4] + '_real_A.jpg', maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d0a5b2",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccdde50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
